{"cells":[{"cell_type":"markdown","source":["# Introduction\n","\n","This code file is to do the preprocessing of original dataset. <br>\n","1. Baseline correction <br>\n","2. SG Smoothing <br>\n","3. Moving Average Smoothing <br>\n","4. Multiplicative Scatter Correction (MSC) <br>\n","5. Extended Multiplicative Scatter Correction (EMSC) <br>\n","6. Standard Normal Variate (SNV) <br>\n","7. Standardization <br>\n","8. Min-max Normalization <br>\n","\n","\n","This way total 9 datasets will be ready to train on models and best one can be used for optimization."],"metadata":{"id":"3DEBiH9u5V6j"},"id":"3DEBiH9u5V6j"},{"cell_type":"code","execution_count":null,"id":"96eb9ffc","metadata":{"id":"96eb9ffc"},"outputs":[],"source":["## Loading Libraries"]},{"cell_type":"code","execution_count":null,"id":"45e9e28d","metadata":{"id":"45e9e28d"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.signal import savgol_filter\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"id":"e505f913","metadata":{"id":"e505f913"},"outputs":[],"source":["## Loading Dataset"]},{"cell_type":"code","execution_count":null,"id":"d85eacd7","metadata":{"id":"d85eacd7","outputId":"be6b9d6a-b3cd-4c04-f8f8-fef3d9d25780"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>499.24539</th>\n","      <th>501.23394</th>\n","      <th>501.2999</th>\n","      <th>503.28818</th>\n","      <th>503.35441</th>\n","      <th>505.34242</th>\n","      <th>505.40892</th>\n","      <th>507.39666</th>\n","      <th>507.46343</th>\n","      <th>509.45089</th>\n","      <th>...</th>\n","      <th>3989.32917</th>\n","      <th>3989.85414</th>\n","      <th>3991.38341</th>\n","      <th>3991.90864</th>\n","      <th>3993.43765</th>\n","      <th>3993.96315</th>\n","      <th>3995.49188</th>\n","      <th>3996.01766</th>\n","      <th>3997.54612</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.285685</td>\n","      <td>0.28567</td>\n","      <td>0.299095</td>\n","      <td>0.31252</td>\n","      <td>0.322775</td>\n","      <td>0.33303</td>\n","      <td>0.325970</td>\n","      <td>0.31891</td>\n","      <td>0.306360</td>\n","      <td>0.29381</td>\n","      <td>...</td>\n","      <td>0.00614</td>\n","      <td>0.006050</td>\n","      <td>0.00596</td>\n","      <td>0.005930</td>\n","      <td>0.00590</td>\n","      <td>0.005950</td>\n","      <td>0.00600</td>\n","      <td>0.006115</td>\n","      <td>0.00623</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.310230</td>\n","      <td>0.30089</td>\n","      <td>0.310420</td>\n","      <td>0.31995</td>\n","      <td>0.326085</td>\n","      <td>0.33222</td>\n","      <td>0.322500</td>\n","      <td>0.31278</td>\n","      <td>0.301910</td>\n","      <td>0.29104</td>\n","      <td>...</td>\n","      <td>0.00665</td>\n","      <td>0.006585</td>\n","      <td>0.00652</td>\n","      <td>0.006555</td>\n","      <td>0.00659</td>\n","      <td>0.006650</td>\n","      <td>0.00671</td>\n","      <td>0.006700</td>\n","      <td>0.00669</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.353515</td>\n","      <td>0.34502</td>\n","      <td>0.344660</td>\n","      <td>0.34430</td>\n","      <td>0.343595</td>\n","      <td>0.34289</td>\n","      <td>0.340165</td>\n","      <td>0.33744</td>\n","      <td>0.333335</td>\n","      <td>0.32923</td>\n","      <td>...</td>\n","      <td>0.00153</td>\n","      <td>0.001465</td>\n","      <td>0.00140</td>\n","      <td>0.001395</td>\n","      <td>0.00139</td>\n","      <td>0.001445</td>\n","      <td>0.00150</td>\n","      <td>0.001565</td>\n","      <td>0.00163</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.244705</td>\n","      <td>0.22002</td>\n","      <td>0.215490</td>\n","      <td>0.21096</td>\n","      <td>0.228045</td>\n","      <td>0.24513</td>\n","      <td>0.260150</td>\n","      <td>0.27517</td>\n","      <td>0.281050</td>\n","      <td>0.28693</td>\n","      <td>...</td>\n","      <td>0.00188</td>\n","      <td>0.001765</td>\n","      <td>0.00165</td>\n","      <td>0.001590</td>\n","      <td>0.00153</td>\n","      <td>0.001585</td>\n","      <td>0.00164</td>\n","      <td>0.001755</td>\n","      <td>0.00187</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.385975</td>\n","      <td>0.39838</td>\n","      <td>0.384900</td>\n","      <td>0.37142</td>\n","      <td>0.358035</td>\n","      <td>0.34465</td>\n","      <td>0.328860</td>\n","      <td>0.31307</td>\n","      <td>0.302525</td>\n","      <td>0.29198</td>\n","      <td>...</td>\n","      <td>0.00014</td>\n","      <td>0.000185</td>\n","      <td>0.00023</td>\n","      <td>0.000230</td>\n","      <td>0.00023</td>\n","      <td>0.000180</td>\n","      <td>0.00013</td>\n","      <td>0.000090</td>\n","      <td>0.00005</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 3407 columns</p>\n","</div>"],"text/plain":["   499.24539  501.23394  501.2999  503.28818  503.35441  505.34242  505.40892  \\\n","0   0.285685    0.28567  0.299095    0.31252   0.322775    0.33303   0.325970   \n","1   0.310230    0.30089  0.310420    0.31995   0.326085    0.33222   0.322500   \n","2   0.353515    0.34502  0.344660    0.34430   0.343595    0.34289   0.340165   \n","3   0.244705    0.22002  0.215490    0.21096   0.228045    0.24513   0.260150   \n","4   0.385975    0.39838  0.384900    0.37142   0.358035    0.34465   0.328860   \n","\n","   507.39666  507.46343  509.45089  ...  3989.32917  3989.85414  3991.38341  \\\n","0    0.31891   0.306360    0.29381  ...     0.00614    0.006050     0.00596   \n","1    0.31278   0.301910    0.29104  ...     0.00665    0.006585     0.00652   \n","2    0.33744   0.333335    0.32923  ...     0.00153    0.001465     0.00140   \n","3    0.27517   0.281050    0.28693  ...     0.00188    0.001765     0.00165   \n","4    0.31307   0.302525    0.29198  ...     0.00014    0.000185     0.00023   \n","\n","   3991.90864  3993.43765  3993.96315  3995.49188  3996.01766  3997.54612  \\\n","0    0.005930     0.00590    0.005950     0.00600    0.006115     0.00623   \n","1    0.006555     0.00659    0.006650     0.00671    0.006700     0.00669   \n","2    0.001395     0.00139    0.001445     0.00150    0.001565     0.00163   \n","3    0.001590     0.00153    0.001585     0.00164    0.001755     0.00187   \n","4    0.000230     0.00023    0.000180     0.00013    0.000090     0.00005   \n","\n","   Target  \n","0     0.0  \n","1     0.0  \n","2     0.0  \n","3     0.0  \n","4     0.0  \n","\n","[5 rows x 3407 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df=pd.read_excel('Dataset O.xlsx', index_col=0)\n","df.head()"]},{"cell_type":"markdown","source":["### P1: Baseline correction\n","\n","It involves removing or reducing a background signal that can obscure the true peaks or features of interest. This process improves the signal-to-noise ratio, making it easier to identify and quantify these features.\n"],"metadata":{"id":"1C_1mPVB6kXL"},"id":"1C_1mPVB6kXL"},{"cell_type":"code","execution_count":null,"id":"d6f951dd","metadata":{"id":"d6f951dd"},"outputs":[],"source":["intensity_df=df.drop(['Target'], axis=1).copy()\n","intensity = intensity_df.astype(float).to_numpy()\n","intensity=pd.DataFrame(intensity).apply(pd.to_numeric, errors='coerce').to_numpy()\n","feature = intensity_df.columns.astype(float).to_numpy(copy=True)"]},{"cell_type":"code","execution_count":null,"id":"fd01cef4","metadata":{"id":"fd01cef4"},"outputs":[],"source":["def baseline_correction(intensity, feature, degree=2):\n","\n","    baseline_corrected = np.zeros_like(intensity)\n","\n","    for i in range(intensity.shape[0]):\n","        coeffs = np.polyfit(feature, intensity[i, :], degree)\n","        baseline = np.polyval(coeffs, feature)\n","        baseline_corrected[i, :] = intensity[i, :] - baseline\n","\n","    return baseline_corrected"]},{"cell_type":"code","execution_count":null,"id":"ab8bff21","metadata":{"id":"ab8bff21"},"outputs":[],"source":["new_intensity=baseline_correction(intensity, feature)\n","df_p=pd.DataFrame(new_intensity, columns=feature)\n","df_p['Target']=df['Target']"]},{"cell_type":"code","execution_count":null,"id":"4959b230","metadata":{"id":"4959b230"},"outputs":[],"source":["df_p.to_excel('Dataset P1.xlsx')"]},{"cell_type":"markdown","source":["### P2: SG Smoothing\n","\n","Savitzky–Golay (SG) filtering, based on local least-squares fitting of the data by polynomials, is a popular method for smoothing data and calculations of derivatives of noisy data."],"metadata":{"id":"n2Hx5aR86p1L"},"id":"n2Hx5aR86p1L"},{"cell_type":"code","execution_count":null,"id":"2a7efe36","metadata":{"id":"2a7efe36"},"outputs":[],"source":["def sg_smoothing(intensity, window_size=7, poly_order=3):\n","\n","    smoothed_data = np.zeros_like(intensity)\n","\n","    for i in range(intensity.shape[0]):\n","        smoothed_data[i, :] = savgol_filter(intensity[i, :], window_size, poly_order)\n","\n","    return smoothed_data"]},{"cell_type":"code","execution_count":null,"id":"3d44c666","metadata":{"id":"3d44c666"},"outputs":[],"source":["new_intensity=sg_smoothing(intensity)\n","df_p=pd.DataFrame(new_intensity, columns=feature)\n","df_p['Target']=df['Target']"]},{"cell_type":"code","execution_count":null,"id":"dad12091","metadata":{"id":"dad12091"},"outputs":[],"source":["df_p.to_excel('Dataset P2.xlsx')"]},{"cell_type":"markdown","source":["### P3: Moving Average Smoothing\n","\n","Moving average smoothing is a technique used to reduce noise and highlight underlying trends in time series data by averaging data points over a specified period."],"metadata":{"id":"cItW2mtG6x3D"},"id":"cItW2mtG6x3D"},{"cell_type":"code","execution_count":null,"id":"4d458a52","metadata":{"id":"4d458a52"},"outputs":[],"source":["def moving_average_smoothing(intensity, window_size=5):\n","\n","    smoothed_data = np.zeros_like(intensity)\n","\n","    for i in range(intensity.shape[0]):\n","        smoothed_data[i, :] = np.convolve(intensity[i, :], np.ones(window_size)/window_size, mode='same')\n","\n","    return smoothed_data"]},{"cell_type":"code","execution_count":null,"id":"890b6c45","metadata":{"id":"890b6c45"},"outputs":[],"source":["new_intensity=moving_average_smoothing(intensity)\n","df_p=pd.DataFrame(new_intensity, columns=feature)\n","df_p['Target']=df['Target']"]},{"cell_type":"code","execution_count":null,"id":"26766644","metadata":{"id":"26766644"},"outputs":[],"source":["df_p.to_excel('Dataset P3.xlsx')"]},{"cell_type":"markdown","source":["### P4: MSC\n","\n","In the context of spectral analysis, \"MSC\" stands for Multiplicative Scatter Correction. MSC is a spectral preprocessing technique used to reduce variations in spectral data caused by factors like particle size and measurement conditions, especially in near-infrared (NIR) spectroscopy."],"metadata":{"id":"gWiQiX7865d7"},"id":"gWiQiX7865d7"},{"cell_type":"code","execution_count":null,"id":"c0cd76b8","metadata":{"id":"c0cd76b8"},"outputs":[],"source":["def msc_correction(intensity):\n","\n","    mean_spectrum = np.mean(intensity, axis=0)\n","    msc_corrected = np.zeros_like(intensity)\n","\n","    for i in range(intensity.shape[0]):\n","        spectrum = intensity[i, :]\n","        msc_corrected[i, :] = spectrum / mean_spectrum\n","\n","    return msc_corrected"]},{"cell_type":"code","execution_count":null,"id":"aba78153","metadata":{"id":"aba78153"},"outputs":[],"source":["new_intensity=msc_correction(intensity)\n","df_p=pd.DataFrame(new_intensity, columns=feature)\n","df_p['Target']=df['Target']"]},{"cell_type":"code","execution_count":null,"id":"4b0fbcb7","metadata":{"id":"4b0fbcb7"},"outputs":[],"source":["df_p.to_excel('Dataset P4.xlsx')"]},{"cell_type":"markdown","source":["### P5: EMSC\n","\n","In spectral analysis, Extended Multiplicative Signal Correction (EMSC) is a preprocessing technique used to isolate and remove various multiplicative effects, particularly those caused by physical phenomena like light scattering, from spectral data."],"metadata":{"id":"16n5czkc7EZ8"},"id":"16n5czkc7EZ8"},{"cell_type":"code","execution_count":null,"id":"8773eebe","metadata":{"id":"8773eebe"},"outputs":[],"source":["def emsc_correction(intensity, poly_order = 2):\n","\n","    mean_spectrum = np.mean(intensity, axis=0)\n","    emsc_corrected = np.zeros_like(intensity)\n","\n","    for i in range(intensity.shape[0]):\n","        spectrum = intensity[i, :]\n","        eps=1e-10\n","        non_zero_spectrum=np.maximum(spectrum, eps)\n","        coeffs = np.polyfit(feature, np.log(non_zero_spectrum), poly_order)\n","        baseline = np.polyval(coeffs, feature)\n","        corrected_spectrum = spectrum / np.exp(baseline)\n","        emsc_corrected[i, :] = corrected_spectrum / np.mean(corrected_spectrum)\n","\n","    return emsc_corrected"]},{"cell_type":"code","execution_count":null,"id":"f73ab7cd","metadata":{"id":"f73ab7cd"},"outputs":[],"source":["new_intensity=emsc_correction(intensity)\n","df_p=pd.DataFrame(new_intensity, columns=feature)\n","df_p['Target']=df['Target']"]},{"cell_type":"code","execution_count":null,"id":"7ffe6774","metadata":{"id":"7ffe6774"},"outputs":[],"source":["df_p.to_excel('Dataset P5.xlsx')"]},{"cell_type":"markdown","source":["### P6: SNV\n","\n","In spectral analysis, Standard Normal Variate (SNV) is a normalization method that corrects spectra for baseline variations and scatter effects. It transforms spectral data so that each spectrum has a mean of 0 and a standard deviation of 1, making intensities comparable across different spectra."],"metadata":{"id":"Cl7Lw4r67KaT"},"id":"Cl7Lw4r67KaT"},{"cell_type":"code","execution_count":null,"id":"7b5f7021","metadata":{"id":"7b5f7021"},"outputs":[],"source":["def snv_correction(intensity):\n","\n","    mean_spectrum = np.mean(intensity, axis=0)\n","    std_spectrum = np.std(intensity, axis=0)\n","    snv_corrected = (intensity - mean_spectrum) / std_spectrum\n","\n","    return snv_corrected"]},{"cell_type":"code","execution_count":null,"id":"467ac4f1","metadata":{"id":"467ac4f1"},"outputs":[],"source":["new_intensity=snv_correction(intensity)\n","df_p=pd.DataFrame(new_intensity, columns=feature)\n","df_p['Target']=df['Target']"]},{"cell_type":"code","execution_count":null,"id":"4c2d0ca9","metadata":{"id":"4c2d0ca9"},"outputs":[],"source":["df_p.to_excel('Dataset P6.xlsx')"]},{"cell_type":"markdown","source":["### P7: Standardization\n","\n","Spectra standardization is a process that aims to make spectral data from different instruments or measurements comparable by reducing variations due to instrument differences, data processing methods, or environmental factors. It involves correcting spectral features, like baseline drift and noise, to align spectra from different sources, allowing for more reliable and consistent analysis and comparison."],"metadata":{"id":"Zg6w2T4b7QuL"},"id":"Zg6w2T4b7QuL"},{"cell_type":"code","execution_count":null,"id":"b4be87ff","metadata":{"id":"b4be87ff"},"outputs":[],"source":["df_p=df.copy(deep=True)"]},{"cell_type":"code","execution_count":null,"id":"390a9d1b","metadata":{"id":"390a9d1b"},"outputs":[],"source":["X=df_p.iloc[:, :-1]\n","Y=df_p.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"id":"50cb18ee","metadata":{"id":"50cb18ee","outputId":"27a33db6-113b-43dc-a79c-64dbb93a8de3"},"outputs":[{"data":{"text/plain":["(179,)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["Y.shape"]},{"cell_type":"code","execution_count":null,"id":"06cecb19","metadata":{"id":"06cecb19"},"outputs":[],"source":["scaler_features = StandardScaler()\n","scaler_target = StandardScaler()"]},{"cell_type":"code","execution_count":null,"id":"90823d7a","metadata":{"id":"90823d7a"},"outputs":[],"source":["df_p.iloc[:, :-1] = scaler_features.fit_transform(X)\n","df_p.iloc[:, -1] = scaler_target.fit_transform(Y.reshape(-1, 1)).flatten()"]},{"cell_type":"code","execution_count":null,"id":"f0aeb054","metadata":{"id":"f0aeb054"},"outputs":[],"source":["df_p.to_excel('Dataset P7.xlsx')"]},{"cell_type":"markdown","source":["### P8: Min-max Normalization\n","\n","Min-max normalization in spectral data, also known as feature scaling, scales the data to a fixed range, typically 0 to 1. This is useful for comparing spectra with varying intensity scales and for machine learning algorithms that perform better with standardized inputs."],"metadata":{"id":"0eneZ5567Zs8"},"id":"0eneZ5567Zs8"},{"cell_type":"code","execution_count":null,"id":"c036bd1e","metadata":{"id":"c036bd1e"},"outputs":[],"source":["df_p=df.copy(deep=True)"]},{"cell_type":"code","execution_count":null,"id":"8817f02d","metadata":{"id":"8817f02d"},"outputs":[],"source":["min_val=(df_p.iloc[:, :-1].min()).min()\n","max_val=(df_p.iloc[:, :-1].max()).max()\n","df_p.iloc[:, :-1]=df_p.iloc[:, :-1].apply(lambda x: (x-min_val)/(max_val-min_val))"]},{"cell_type":"code","execution_count":null,"id":"0e735d80","metadata":{"id":"0e735d80"},"outputs":[],"source":["df_p.to_excel('Dataset P8.xlsx')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}